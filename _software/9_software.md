---
layout: post
title: CompStats
description: Python library for comparing algorithms' performance
---

Collaborative competitions have gained popularity in the scientific and technological fields. These competitions involve defining tasks, selecting evaluation scores, and devising result verification methods. In the standard scenario, participants receive a training set and are expected to provide a solution for a held-out dataset kept by organizers. An essential challenge for organizers arises when comparing algorithms' performance, assessing multiple participants, and ranking them. Statistical tools are often used for this purpose; however, traditional statistical methods often fail to capture decisive differences between systems' performance. CompStats implements an evaluation methodology for statistically analyzing competition results and competition. CompStats offers several advantages, including off-the-shell comparisons with correction mechanisms and the inclusion of confidence intervals.

Source Code in <a class="social-button github" href="https://www.github.com/INGEOTEC/compstats" itemprop="sameAs" target="_blank"> <i class="fab fa-github"></i>

The documentation is on [readthedocs](https://compstats.readthedocs.io).